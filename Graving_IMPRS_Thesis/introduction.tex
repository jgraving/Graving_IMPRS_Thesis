	\chapter*{Introduction}
    \addcontentsline{toc}{chapter}{Introduction}
Measuring and modeling behavior are fundamental problems for the study of ecology and neuroscience \citep{berman2018measuring, brown2018ethology}. In general, these methodological areas seek to develop techniques capable of answering a straightforward set of questions: Where are individuals located in space? Who are those individuals? And what are they doing? Perhaps unsurprisingly, these three fundamental questions overlap with similar unsolved problems in computer vision \citep{dell2014automated, lecun2015deep} including object detection and tracking, facial recognition and object classification, as well as pose estimation and action recognition. Despite the concrete, real-world nature of these problems, only very recently have the computational algorithms for solving these tasks reached the same level of quality as that of manual human annotation \citep{lecun2015deep, goodfellow2016deep}. This increase in quality is largely due to the democratization and wide-spread adoption of deep learning algorithms, a class of computational models that are capable of automatically detecting complex patterns and can scale to arbitrarily large and high-dimensional datasets \citep{lecun2015deep, goodfellow2016deep}. Consequently, a large body of computer science literature with general-purpose algorithms for solving these previously-unsolved tasks now exists, and this progress is only just beginning to be adapted to study animal behavior \citep{mathis2018deeplabcut, pereira2019fast, graving2019deepposekit, gunel2019deepfly3d} --- which brings with it many additional unsolved problems \citep{graving2019deepposekit, mathis2020deep, mathis2020primer}.

The overarching goal of this thesis has been to contribute to this growing body of work by developing general-purpose, open-source software and algorithms that allow researchers to apply computational tools to measure and model behavior as well as to illustrate the power of these tools to address questions that were previously unanswerable. Over the course of my PhD, I built on the existing deep learning and computer vision literature to develop new software and algorithms for solving these problems. This involved collaborations with other researchers to apply these methods to detect, track, and estimate the body posture of animals both in the laboratory and the field. Additionally, I developed methods for summarizing and interpreting these data using probabilistic deep learning models, which draw on fundamental ideas from Bayesian statistics and information theory. Together these methods have allowed researchers to measure behavior in experimental scenarios that were previously intractable and have helped to make meaningful biological inferences using large, complex, high-dimensional data sets.

Just a couple decades ago, the use of computer vision for the study of animal behavior was relatively uncommon \citep{dell2014automated}. However, as computational hardware and software have matured and became more accessible, so have the methods used to quantify movement and extract insights from behavioral experiments. Studying behavior with computer vision methods has become increasingly common in recent years, and the field of animal behavior has evolved rapidly in response \citep{anderson2014toward, berman2018measuring, brown2018ethology}. This is an extremely exciting and active research area with researchers continuously advancing a range of methods to automatically measure behavior in almost any scenario \citep{dell2014automated, anderson2014toward, graving2019deepposekit, mathis2020deep}. For example, many of the conventional approaches developed only a few years ago are now almost completely obsolete. Some of the most prevalent approaches now focus on the use of deep learning for the measurement and modeling of animal locomotion \citep{graving2019deepposekit, mathis2020deep, luxem2020identifying, graving2020vaesne} --- including automated motion capture and tracking of animal movements in the laboratory and in the wild \citep{nath2018, graving2019deepposekit, francisco2020high}. 

Deep learning has begun to revolutionize science as we know it \citep{lecun2015deep}. Rapid advances in hardware and software, combined with a research community focused on open-source and open-access philosophies, have democratized this class of machine learning algorithms. Consequently, this has made the use of deep learning tools commonplace across the natural sciences. These general-purpose algorithms have been applied to a wide array of problems in computer vision, natural language processing, and audio recognition (reviewed by \citealt{lecun2015deep}). With the right data, a deep learning model has the potential to solve nearly any computational task with relatively minimal effort---even those tasks once thought to always require human-level intelligence. The study of animal behavior is no different, and deep learning has dramatically impacted this interdisciplinary field in a short period of time \citep{graving2019deepposekit, mathis2020deep}. Deep learning has already revolutionized the study of animal behavior as a tool for both quantifying behavior \citep{mathis2018deeplabcut, pereira2019fast, romero2018idtracker, graving2019deepposekit} as well as understanding behavior through data-driven modeling \citep{johnson2016composing, luxem2020identifying, graving2020vaesne} and will continue to advance the study of behavior for the foreseeable future. 

Here, in this thesis, I provide an update on the status of computer vision-based methods in the behavioral sciences. I focus on a few of the most prominent methods in this area of research, highlight some of the most promising applications for these technologies, and introduce several advances in the use of computer vision and deep learning-based methods to automatically measure animal locomotion and body posture. In Chapter 1, I discuss methods for tracking the behavior of animals with conventional computer vision techniques. I provide an overview of existing methods and discuss the motivations for using computer vision over other methods for behavioral quantification. Then I software for marker-based spatial localization and individual identification using 2D barcode tags \citep{graving2017pinpoint}, and, in collaboration with colleagues, apply this software to automatically track large groups of individuals for long-term behavioral studies in captive bird populations \citep{alarcon2018automated}. In this work, we also demonstrate how the data can be used to reconstruct social networks. This system has already been used to reveal fundamental insights about the behavior of these bird populations \citep{maldonado2018experimental}, and will continue to do so in the future. 

In Chapter 2, I develop image-based approaches using deep learning to measure detailed information about animal body posture. These methods were only recently adapted from the computer science literature on human pose estimation and have seen rapid progress since then. I discuss how these approaches compare with conventional methods for behavioral quantification, and I review currently available methods for deep learning-based pose estimation. Additionally, I identify several gaps in these existing methods and introduce a deep learning-based software toolkit, called DeepPoseKit, with general-purpose methods for the automated measurement of animal body posture. Within this toolkit, several technical advances are introduced to the field of pose estimation that address many of the limitations with existing methods, and, together with colleagues, we compare these methods with previous techniques and apply them to new datasets \citep{graving2019deepposekit}. These methods have already been applied to ongoing research projects. For example, I am collaborating with colleagues to study energy saving strategies in schooling fish as well as collective predator detection in herds of ungulates in the wild --- two unsolved research topics that would not have been tractable without these methods.

In Chapter 3, I discuss methods for decomposing these detailed postural data into their underlying components by identifying stereotyped behavioral motifs, or behavioral modes, directly from data. To accomplish this, I introduce a new deep learning model, called VAE-SNE, which serves as a tool for the general-purpose analysis and interpretation of high-dimensional data. I then demonstrate the utility of this algorithm for different tasks across multiple domains in the life sciences. In particular, I use VAE-SNE to perform unsupervised action recognition by automatically segmenting high-dimensional behavioral data into known stereotyped actions, such as locomotion, grooming etc., by automatically compressing and clustering high-dimensional body posture dynamics. 

Throughout the thesis, I discuss how modern computer vision-based methods, together with other computational technologies, such as virtual reality and drone-based imaging, allow for systems for real-time, automated, and efficient measurement and modeling of complex behavioral patterns, such as collective and social behavior, both in laboratory and field settings. In addition to providing an overview of current methods that utilize deep learning for studying behavior, I discuss the future of deep learning as a set of tools for measuring and modeling the behavior of animals across multiple scales of biological complexity as well as how we might evolve, and improve upon, existing methods.
